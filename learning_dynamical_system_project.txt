###  Update Meeting 26-03-2025  ###
TO_DO: - Test out RT-KalmanNet vs KalmanNet, by evaluating both set of features available ({F1,F2,F4}, {F1,F3,F4})** on
         the Synthetic NL model and the Lorenz attractor.
       - Evaluate MSE, std_dev of MSE, comp_time, std_dev of comp_time
       - Plot c_t realizations, one for each model
       - Report the results on a one page presentation, displaying the numerical results on a table and the realizations
         on plots
       - It is requested a code explanation too (How do we arrange it?)
         Explain the following files: 'main_robust_KNet.ipynb', 'robust_kalman.py', 'RT_KalmanNet_nn.py', 'Synthetic_NL_model/parameters.py'


** the actual set of features implemented on KalmanNet are {F1,F2,F3,F4}, thus we must compare with only this set of features


Updated TO_DO:  Sasa -> Implement and test Lorenz Attractor for both models
                Tommi -> Evaluate MSE, ... using pandas to save them (additionally test different Q and R to test out the robustness of RT_KNet)
                Ricky -> Write the one page presentation with two main tables, one for each ss model, each composed by two main colums, one for KNet and one for RT_KNet.
                         Add the plots for the c_t realizations too.(tabella fatta)

TO DO: 21/04/2025 (monday)
- use training sequences longer to see if convergence effect can bi mitigated
- see how the mse is computed in kalmanet (if they throw away the convergence part)
-end the presentation outline and set the meeting


--------------------------------------------------------PRESENTATION OUTLINE------------------------------------------------------------------------------------------------
1) Recall the requested task in the last meeting
2) Specify that we have benchmarked the two archs also with REKF (which was not requested)
3) Summary of what we have added on the code. In particular we have done:
	- Lorenz atractor implementation for the three arcs
	- we have inserted graphs for C_t in RT-KalmanNet
	- improvements of data visualization ( Created dataframe to acquire all MSE and computational time for the three archs and for both models)
	
4) Explain the obtained results (specify the following observations):
	-Synthetic NL model: RT-KalmanNet and Kalman-Net performs better compared with REKF this is expected because the last one is not learning from
	data, has a deterministic and fixed C_t which does not vary over time learning from data, KalmanNet is faster than the other two models and this 
	is expected because a DNN is more complex w.r.t to the GRU and in addition we think they use more optimized functions w.r.t to us
	
	-Lorenz attractor , for what concern the computational time the same considerations as above holds.	

5) Explain the code, in particular show:
	-show how to create a parameters.py for the required model -> specifically stay aware of the f and h functions -> (computational graph problems) 
	-Go to the notebook and show how it works for us -> how to import the model and launch it -> creating of the datasets -> changing the architecture
		-> training and validating the RT Kalmanet
	- a quick overview of the files robust_kalman.py and RT_KalmanNet_nn.py (first translation of REKF and second specify the NN architecture)